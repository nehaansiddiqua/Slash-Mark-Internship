{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYcceKQ5zRrn3yb/RB44b0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nehaansiddiqua/Slash-Mark-Internship/blob/main/Slash_Mark_Task_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epBWwTCoOfCF",
        "outputId": "aa923c21-175c-4190-8b54-7b624ce7d659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 9s 270ms/step - loss: 0.1357 - accuracy: 0.9787 - val_loss: 2.9830e-05 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 7s 277ms/step - loss: 4.0132e-06 - accuracy: 1.0000 - val_loss: 1.3025e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 4s 172ms/step - loss: 9.2012e-08 - accuracy: 1.0000 - val_loss: 6.2868e-08 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 4s 170ms/step - loss: 6.4869e-08 - accuracy: 1.0000 - val_loss: 5.6878e-08 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 6s 232ms/step - loss: 6.0780e-08 - accuracy: 1.0000 - val_loss: 5.4216e-08 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 4s 170ms/step - loss: 5.7941e-08 - accuracy: 1.0000 - val_loss: 5.1695e-08 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 4s 168ms/step - loss: 5.5106e-08 - accuracy: 1.0000 - val_loss: 4.8946e-08 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 5.2091e-08 - accuracy: 1.0000 - val_loss: 4.6136e-08 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 4.8986e-08 - accuracy: 1.0000 - val_loss: 4.3286e-08 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 4.5866e-08 - accuracy: 1.0000 - val_loss: 4.0628e-08 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 6s 230ms/step - loss: 4.3540e-08 - accuracy: 1.0000 - val_loss: 3.8972e-08 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 4s 169ms/step - loss: 4.1840e-08 - accuracy: 1.0000 - val_loss: 3.7413e-08 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 5s 183ms/step - loss: 4.0135e-08 - accuracy: 1.0000 - val_loss: 3.5889e-08 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 5s 209ms/step - loss: 3.8441e-08 - accuracy: 1.0000 - val_loss: 3.4326e-08 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 4s 171ms/step - loss: 3.6734e-08 - accuracy: 1.0000 - val_loss: 3.2720e-08 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 5s 206ms/step - loss: 3.4976e-08 - accuracy: 1.0000 - val_loss: 3.1158e-08 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 5s 190ms/step - loss: 3.3255e-08 - accuracy: 1.0000 - val_loss: 2.9548e-08 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 4s 170ms/step - loss: 3.1512e-08 - accuracy: 1.0000 - val_loss: 2.7955e-08 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 5s 219ms/step - loss: 2.9770e-08 - accuracy: 1.0000 - val_loss: 2.6403e-08 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 5s 182ms/step - loss: 2.8074e-08 - accuracy: 1.0000 - val_loss: 2.4826e-08 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Generate synthetic data for demonstration purposes\n",
        "# Here, we'll create two types of images: squares and circles\n",
        "# Squares will be labeled as class 0, and circles as class 1\n",
        "\n",
        "# Function to generate square images\n",
        "def generate_square(size):\n",
        "    image = np.zeros((size, size))\n",
        "    start = size // 4\n",
        "    end = 3 * size // 4\n",
        "    image[start:end, start:end] = 1\n",
        "    return image\n",
        "\n",
        "# Function to generate circle images\n",
        "def generate_circle(size):\n",
        "    image = np.zeros((size, size))\n",
        "    center = size // 2\n",
        "    radius = size // 4\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            if (i - center)**2 + (j - center)**2 <= radius**2:\n",
        "                image[i, j] = 1\n",
        "    return image\n",
        "\n",
        "# Generate synthetic images and labels\n",
        "num_samples = 1000\n",
        "image_size = 64\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for _ in range(num_samples // 2):\n",
        "    square = generate_square(image_size)\n",
        "    X.append(square)\n",
        "    y.append(0)  # Label square as class 0\n",
        "\n",
        "for _ in range(num_samples // 2):\n",
        "    circle = generate_circle(image_size)\n",
        "    X.append(circle)\n",
        "    y.append(1)  # Label circle as class 1\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X).reshape(-1, image_size, image_size, 1)  # Reshape for Conv2D input\n",
        "y = np.array(y)\n",
        "\n",
        "# Shuffle the data\n",
        "shuffle_indices = np.random.permutation(len(X))\n",
        "X = X[shuffle_indices]\n",
        "y = y[shuffle_indices]\n",
        "\n",
        "# Define constants\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('synthetic_images_model.h5')\n"
      ]
    }
  ]
}